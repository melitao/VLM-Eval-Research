{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b57e4e-3ac6-4b30-85a7-a1ccf1ed9927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\n",
      "VLAT JSON expected at: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\\VLAT\\vlat_skip.json\n",
      "CALVI JSON expected at: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\\CALVI\\calvi.json\n"
     ]
    }
   ],
   "source": [
    "# === Config & imports ===\n",
    "import os, io, json, time, random, traceback, base64\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Paths (relative to this notebook's folder)\n",
    "NB_DIR = Path.cwd()\n",
    "VLAT_JSON = (NB_DIR.parent / 'data' / 'VLAT' / 'vlat_skip.json')\n",
    "CALVI_JSON = (NB_DIR.parent / 'data' / 'CALVI' / 'calvi.json')\n",
    "\n",
    "# Ollama chat endpoint / model\n",
    "API_URL = 'http://localhost:11434/api/chat'\n",
    "MODEL   = 'llava:7b'\n",
    "\n",
    "# Experiment options\n",
    "NUM_RUNS     = 3         # number of repetitions over the dataset\n",
    "MAX_RETRIES  = 3         # retries for transient API errors\n",
    "RETRY_DELAY  = 2         # seconds\n",
    "TEMPERATURE  = 0.0       # deterministic\n",
    "MAX_TOKENS   = 300       # response cap (if your server honors it)\n",
    "\n",
    "# Prompts\n",
    "VLAT_PROMPT = (\n",
    "    \"I am about to show you an image and ask you a multiple choice question about that image. \"\n",
    "    \"Read the question carefully, examine the chart, then answer with only the choice text.\"\n",
    ")\n",
    "CALVI_PROMPT = (\n",
    "    \"You will see a visualization and a multiple choice question. \"\n",
    "    \"Reason step by step and return only the option you believe is correct.\"\n",
    ")\n",
    "\n",
    "print('Notebook directory:', NB_DIR)\n",
    "print('VLAT JSON expected at:', VLAT_JSON)\n",
    "print('CALVI JSON expected at:', CALVI_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb2d06bb-4f71-42b1-bee9-52bf1cd06bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Utilities: ping server, image encoding, robust JSON loading ===\n",
    "def ping_ollama(url: str = API_URL) -> bool:\n",
    "    try:\n",
    "        r = requests.get(url.replace('/api/chat','/api/tags'), timeout=5)\n",
    "        return r.ok\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def b64_from_file(path: Path) -> str:\n",
    "    with open(path, 'rb') as f:\n",
    "        return base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "def resolve_image_paths(json_path: Path, questions: List[Dict[str,Any]]) -> List[Dict[str,Any]]:\n",
    "    base = json_path.parent\n",
    "    for q in questions:\n",
    "        raw = q.get('image_path', '')\n",
    "        p = Path(raw)\n",
    "        if not p.is_absolute():\n",
    "            candidates = [\n",
    "                base / p,                       # same folder as JSON\n",
    "                base / 'images' / p.name,       # a common layout\n",
    "                base.parent / p,                # one level up\n",
    "                Path.cwd() / p                  # notebook CWD (fallback)\n",
    "            ]\n",
    "            chosen = None\n",
    "            for c in candidates:\n",
    "                if c.exists():\n",
    "                    chosen = c\n",
    "                    break\n",
    "            if chosen is None:\n",
    "                # keep best-guess (relative to JSON folder) so errors are informative\n",
    "                chosen = (base / p)\n",
    "            q['image_path'] = str(chosen)\n",
    "        else:\n",
    "            q['image_path'] = str(p)\n",
    "    return questions\n",
    "\n",
    "def load_questions_file(file_path: Path) -> List[Dict[str,Any]]:\n",
    "    file_path = Path(file_path)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    # expected schema: top-level key 'questions'\n",
    "    items = data.get('questions', data)\n",
    "    if not isinstance(items, list):\n",
    "        raise ValueError('Expected a list under key \"questions\" or the file to be a list of items.')\n",
    "    return resolve_image_paths(file_path, items)\n",
    "\n",
    "def call_llava(image_path: Path, prompt: str) -> str:\n",
    "    # encode image\n",
    "    img_b64 = b64_from_file(image_path)\n",
    "    payload = {\n",
    "        'model': MODEL,\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "                'images': [img_b64]\n",
    "            }\n",
    "        ],\n",
    "        'stream': False,\n",
    "        'options': {\n",
    "            'temperature': TEMPERATURE,\n",
    "        }\n",
    "    }\n",
    "    for attempt in range(1, MAX_RETRIES+1):\n",
    "        try:\n",
    "            r = requests.post(API_URL, json=payload, timeout=120)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            return data.get('message',{}).get('content','')\n",
    "        except Exception as e:\n",
    "            if attempt == MAX_RETRIES:\n",
    "                raise\n",
    "            time.sleep(RETRY_DELAY)\n",
    "    return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da98ea66-3580-4e60-b836-332142c01b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running? -> True\n",
      "VLAT JSON exists? -> True\n",
      "CALVI JSON exists? -> True\n"
     ]
    }
   ],
   "source": [
    "# === Sanity checks ===\n",
    "print('Ollama running? ->', ping_ollama())\n",
    "print('VLAT JSON exists? ->', VLAT_JSON.exists())\n",
    "print('CALVI JSON exists? ->', CALVI_JSON.exists())\n",
    "\n",
    "# If these return False, fix the paths above or move your files accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce77575b-3e41-4823-8a8e-b07897e0c215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample VLAT item:\n",
      "  id: 1\n",
      "  question: What was the price of a barrel of oil in February 2015?\n",
      "  image_path: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\\VLAT\\images\\LineChart.png\n",
      "Image exists? -> True\n",
      "Sample CALVI item:\n",
      "  id: 43\n",
      "  question: What is the trend sales in gift shop A from Jan to Dec?\n",
      "  image_path: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\\CALVI\\images\\question43.png\n",
      "Image exists? -> True\n"
     ]
    }
   ],
   "source": [
    "# === Peek at the first question and verify its image path resolution ===\n",
    "try:\n",
    "    vlat_qs = load_questions_file(VLAT_JSON)\n",
    "    if not vlat_qs:\n",
    "        print('VLAT has 0 questions!')\n",
    "    else:\n",
    "        q0 = vlat_qs[0]\n",
    "        print('Sample VLAT item:')\n",
    "        for k in ['id','question','image_path']:\n",
    "            print(' ', k+':', q0.get(k))\n",
    "        print('Image exists? ->', Path(q0['image_path']).exists())\n",
    "except Exception as e:\n",
    "    print('Error loading VLAT:', e)\n",
    "\n",
    "try:\n",
    "    calvi_qs = load_questions_file(CALVI_JSON)\n",
    "    if not calvi_qs:\n",
    "        print('CALVI has 0 questions!')\n",
    "    else:\n",
    "        q0 = calvi_qs[0]\n",
    "        print('Sample CALVI item:')\n",
    "        for k in ['id','question','image_path']:\n",
    "            print(' ', k+':', q0.get(k))\n",
    "        print('Image exists? ->', Path(q0['image_path']).exists())\n",
    "except Exception as e:\n",
    "    print('Error loading CALVI:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9995e4f-a1c1-49db-a91d-25b27f344bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Main experiment runner ===\n",
    "import csv\n",
    "\n",
    "def run_experiment(name: str, dataset_path: Path, prompt: str, out_dir: Path = NB_DIR / 'results'):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    log_path = out_dir / f'{name}_runs.csv'\n",
    "\n",
    "    questions = load_questions_file(dataset_path)\n",
    "    print(f'Starting {name} with {len(questions)} questions; results ->', log_path)\n",
    "\n",
    "    with open(log_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\n",
    "            'run','qid','image_path','question','model_answer','error'\n",
    "        ])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for run_idx in range(1, NUM_RUNS+1):\n",
    "            print(f'--- Run {run_idx}/{NUM_RUNS} ---')\n",
    "            for i, q in enumerate(questions, 1):\n",
    "                qid = q.get('id', f'{name}_{i}')\n",
    "                img = Path(q['image_path'])\n",
    "                try:\n",
    "                    if not img.exists():\n",
    "                        raise FileNotFoundError(f'Image not found: {img}')\n",
    "                    ans = call_llava(img, prompt + \"\\n\\nQuestion: \" + q.get('question',''))\n",
    "                    writer.writerow({\n",
    "                        'run': run_idx,\n",
    "                        'qid': qid,\n",
    "                        'image_path': str(img),\n",
    "                        'question': q.get('question',''),\n",
    "                        'model_answer': ans,\n",
    "                        'error': ''\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    writer.writerow({\n",
    "                        'run': run_idx,\n",
    "                        'qid': qid,\n",
    "                        'image_path': str(img),\n",
    "                        'question': q.get('question',''),\n",
    "                        'model_answer': '',\n",
    "                        'error': str(e)\n",
    "                    })\n",
    "                    print('Error:', e)\n",
    "\n",
    "    print('Done:', log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c095e0-5a92-4d73-9521-789fff75914d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting VLAT with 53 questions; results -> C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\VLAT_runs.csv\n",
      "--- Run 1/3 ---\n",
      "--- Run 2/3 ---\n",
      "--- Run 3/3 ---\n",
      "Done: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\VLAT_runs.csv\n",
      "Starting CALVI with 45 questions; results -> C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\CALVI_runs.csv\n",
      "--- Run 1/3 ---\n",
      "--- Run 2/3 ---\n",
      "--- Run 3/3 ---\n",
      "Done: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\CALVI_runs.csv\n",
      "Ready. Uncomment the two lines above to start the runs once the sanity checks show True/exists.\n"
     ]
    }
   ],
   "source": [
    "# === Run experiments (uncomment to execute) ===\n",
    "run_experiment('VLAT', VLAT_JSON, VLAT_PROMPT)\n",
    "run_experiment('CALVI', CALVI_JSON, CALVI_PROMPT)\n",
    "\n",
    "print('Ready. Uncomment the two lines above to start the runs once the sanity checks show True/exists.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a81bc-afa9-4a6f-a3ee-4fbc39f29e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
