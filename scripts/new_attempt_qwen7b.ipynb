{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b6bba4-402f-404b-88fb-a1a9ee82201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, csv, time, random, base64, re\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "\n",
    "MODEL_NAME = \"qwen2.5vl:7b\"\n",
    "OLLAMA_HOST = \"http://localhost:11434\"\n",
    "USE_CHAT_API = True\n",
    "STREAM = False\n",
    "\n",
    "IMAGE_ROOT = Path(r\"C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\")\n",
    "VLAT_JSON  = Path(r\"C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\\VLAT\\vlat_skip_orig.json\")\n",
    "CALVI_JSON = Path(r\"C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\\CALVI\\calvi_orig.json\")\n",
    "\n",
    "OUT_VLAT = IMAGE_ROOT.parent / \"Output\" / \"VLAT\" / \"Qwen2.5vl_7b_Eval\" / \"Random\"\n",
    "OUT_CALVI = IMAGE_ROOT.parent / \"Output\" / \"CALVI\" / \"Qwen2.5vl_7b_Eval\" / \"Random\"\n",
    "\n",
    "NUM_RUNS = 10\n",
    "SLEEP_MIN_SEC = 5\n",
    "SLEEP_MAX_SEC = 10\n",
    "BASE_SEED = 12345\n",
    "REQUEST_TIMEOUT = 600\n",
    "\n",
    "VLAT_PROMPT = (\n",
    "\"\"\"I am about to show you an image and ask you a multiple choice question about that image. \n",
    "Please structure your response in the following format:\n",
    "Answer: [Enter the exact text of your chosen option]\n",
    "Explanation: [Provide your reasoning]\n",
    "Select the BEST answer, based only on the chart and not external knowledge. DO NOT GUESS.\n",
    "If you are not sure about your answer or your answer is based on a guess, select \"Omit\".\n",
    "Choose your answer ONLY from the provided options.\"\"\"\n",
    ")\n",
    "\n",
    "CALVI_PROMPT = (\n",
    "\"\"\"I am about to show you an image and ask you a multiple choice question about that image. \n",
    "Please structure your response in the following format:\n",
    "Answer: [Enter the exact text of your chosen option(s)]\n",
    "Explanation: [Provide your reasoning]\n",
    "Select the BEST answer, based only on the chart and not external knowledge.\n",
    "Choose your answer ONLY from the provided options.\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd86bd6-05e5-4dd2-9c5b-d6bec3764ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Performance & pacing controls (added) ===\n",
    "# Timeout for Ollama HTTP requests: (connect, read) seconds\n",
    "REQUEST_TIMEOUT = (30, 120)\n",
    "\n",
    "# Random short break between batches to let the system cool off / avoid long continuous runs\n",
    "SLEEP_MIN_SEC = 6\n",
    "SLEEP_MAX_SEC = 12\n",
    "\n",
    "# Add an extra mid-run pause by splitting the workload into an additional chunk\n",
    "EXTRA_BATCH_CHUNK = 20   # set to 0 to disable\n",
    "\n",
    "# Pause after every batch instead of only after the first one\n",
    "PAUSE_EVERY_BATCH = True\n",
    "\n",
    "# Retry failed requests a couple of times instead of giving up immediately\n",
    "MAX_RETRIES = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb0d1f9-924d-4621-9682-7179586824bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define _sleep_between to use the (possibly updated) SLEEP_* values\n",
    "def _sleep_between(min_s=SLEEP_MIN_SEC, max_s=SLEEP_MAX_SEC):\n",
    "    import random, time\n",
    "    try:\n",
    "        dur = random.uniform(min_s, max_s)\n",
    "        print(f\"[break] Pausing for {dur:.1f}s to cool down...\")\n",
    "        time.sleep(dur)\n",
    "    except Exception as e:\n",
    "        print(f\"[break] Skip sleep due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1cbaeb-e329-49d2-af23-627a8cdb13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _chunk_slices(total: int, plan: List[Any]) -> List[Tuple[int, int]]:\n",
    "    out, start, remain = [], 0, total\n",
    "    for p in (plan or []):\n",
    "        n = remain if (p == \"rest\") else min(int(p), remain)\n",
    "        if n <= 0:\n",
    "            break\n",
    "        out.append((start, start + n))\n",
    "        start += n\n",
    "        remain -= n\n",
    "        if remain <= 0:\n",
    "            break\n",
    "    if not out and total > 0:\n",
    "        out = [(0, total)]\n",
    "    return out\n",
    "\n",
    "def _sleep_between(min_s=SLEEP_MIN_SEC, max_s=SLEEP_MAX_SEC):\n",
    "    dur = random.randint(int(min_s), int(max_s))\n",
    "    print(f\"Cooling down for {dur} seconds to avoid timeouts...\")\n",
    "    time.sleep(dur)\n",
    "\n",
    "def _fieldnames_for_dataset(name: str) -> List[str]:\n",
    "    base = [\n",
    "        \"id\",\"testname\",\"question\",\"Chart_type\",\"Task\",\n",
    "        \"options\",\"correct_answer\",\"model_answer\",\"is_correct\",\n",
    "        \"image_path\",\"elapsed_seconds\",\"response_raw\"\n",
    "    ]\n",
    "    if name.upper() == \"CALVI\":\n",
    "        i = base.index(\"correct_answer\") + 1\n",
    "        base[i:i] = [\"Misleader\",\"wrong_due_to_misleader\"]\n",
    "    return base\n",
    "\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _load_json(path: Path) -> Dict[str, Any]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def _read_image_b64(path: Path) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7353cd58-0951-4054-a5bd-ca8185ee9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _base_prompt(q: Dict[str, Any]) -> str:\n",
    "    opts = q.get(\"options\", [])\n",
    "    letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    lines = [\n",
    "        f\"Question: {q.get('question','').strip()}\",\n",
    "        \"\",\n",
    "        \"Options:\"\n",
    "    ]\n",
    "    for i, opt in enumerate(opts):\n",
    "        lines.append(f\"{letters[i]}. {opt}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _format_prompt(q: Dict[str, Any], prepend: Optional[str] = None) -> str:\n",
    "    core = _base_prompt(q)\n",
    "    if prepend:\n",
    "        return f\"{prepend.strip()}\\n\\n{core}\"\n",
    "    return core\n",
    "\n",
    "def _normalize(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s.strip().lower())\n",
    "\n",
    "def _parse_model_answer(raw: str, options: List[str]) -> str:\n",
    "    if not raw:\n",
    "        return \"\"\n",
    "    text = raw.strip()\n",
    "\n",
    "    m = re.search(r\"^answer\\s*:\\s*(.+)$\", text, re.IGNORECASE | re.MULTILINE)\n",
    "    if m:\n",
    "        ans_txt = m.group(1).strip().strip('\"').strip(\"'\")\n",
    "        ans_txt = re.sub(r\"^\\[(.*)\\]$\", r\"\\1\", ans_txt).strip()\n",
    "\n",
    "        norm_ans = _normalize(ans_txt)\n",
    "        for opt in options:\n",
    "            if _normalize(opt) == norm_ans:\n",
    "                return opt\n",
    "        for opt in options:\n",
    "            if _normalize(opt) in norm_ans or norm_ans in _normalize(opt):\n",
    "                return opt\n",
    "        if re.fullmatch(r\"[A-Za-z]\", ans_txt):\n",
    "            idx = ord(ans_txt.upper()) - ord('A')\n",
    "            if 0 <= idx < len(options):\n",
    "                return options[idx]\n",
    "        return ans_txt\n",
    "\n",
    "    m2 = re.search(r\"\\b([A-H])\\b\", text, re.IGNORECASE)\n",
    "    if m2:\n",
    "        idx = ord(m2.group(1).upper()) - ord('A')\n",
    "        if 0 <= idx < len(options):\n",
    "            return options[idx]\n",
    "\n",
    "    lowered = _normalize(text)\n",
    "    for opt in options:\n",
    "        if _normalize(opt) in lowered:\n",
    "            return opt\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210395ee-f781-4d8e-afcd-ee6368800bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ollama_chat(prompt: str, images_b64: List[str]) -> str:\n",
    "    url = f\"{OLLAMA_HOST}/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"stream\": False,\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "            \"images\": images_b64 if images_b64 else None\n",
    "        }]\n",
    "    }\n",
    "    if payload[\"messages\"][0][\"images\"] is None:\n",
    "        del payload[\"messages\"][0][\"images\"]\n",
    "    r = requests.post(url, json=payload, timeout=REQUEST_TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data.get(\"message\", {}).get(\"content\", \"\")\n",
    "\n",
    "def _ollama_generate(prompt: str, images_b64: List[str]) -> str:\n",
    "    url = f\"{OLLAMA_HOST}/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": prompt,\n",
    "        \"images\": images_b64 if images_b64 else None,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    if payload[\"images\"] is None:\n",
    "        del payload[\"images\"]\n",
    "    r = requests.post(url, json=payload, timeout=REQUEST_TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data.get(\"response\", \"\")\n",
    "\n",
    "def _resolve_image(img_rel: str) -> Path | None:\n",
    "    img_rel_norm = str(img_rel).replace(\"\\\\\", \"/\")\n",
    "    p = Path(img_rel_norm)\n",
    "    candidates = []\n",
    "\n",
    "    if p.is_absolute():\n",
    "        candidates.append(p)\n",
    "\n",
    "    candidates.append(IMAGE_ROOT / p)\n",
    "\n",
    "    parts = p.parts\n",
    "    name = p.name\n",
    "    dataset = parts[0] if parts else None\n",
    "    if dataset in {\"VLAT\", \"CALVI\"}:\n",
    "        candidates.append(IMAGE_ROOT / dataset / \"images\" / name)\n",
    "\n",
    "    candidates.append(IMAGE_ROOT / \"data\" / p)\n",
    "    if dataset in {\"VLAT\", \"CALVI\"}:\n",
    "        candidates.append(IMAGE_ROOT / \"data\" / dataset / \"images\" / name)\n",
    "\n",
    "    seen = set()\n",
    "    for c in candidates:\n",
    "        if c in seen:\n",
    "            continue\n",
    "        seen.add(c)\n",
    "        if c.exists():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def call_qwen(question: Dict[str, Any], prepend_prompt: Optional[str] = None) -> str:\n",
    "    prompt = _format_prompt(question, prepend=prepend_prompt)\n",
    "    images_b64 = []\n",
    "\n",
    "    image_path = question.get(\"image_path\")\n",
    "    if image_path:\n",
    "        resolved = _resolve_image(image_path)\n",
    "        if resolved:\n",
    "            try:\n",
    "                images_b64.append(_read_image_b64(resolved))\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Could not read image {resolved}: {e}\")\n",
    "        else:\n",
    "            print(f\"[WARN] Image file not found (tried common locations) -> '{image_path}'\")\n",
    "\n",
    "    try:\n",
    "        if USE_CHAT_API:\n",
    "            return _ollama_chat(prompt, images_b64)\n",
    "        else:\n",
    "            return _ollama_generate(prompt, images_b64)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Ollama request failed: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e3f72b-de18-4f12-a429-39b649eb6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_row(writer: csv.DictWriter, row: Dict[str, Any], f):\n",
    "    writer.writerow(row)\n",
    "    f.flush()\n",
    "\n",
    "def _eval_one_run(dataset_name: str, qlist: List[Dict[str, Any]], out_csv_path: Path, run_index: int, prepend_prompt: Optional[str] = None):\n",
    "    _ensure_dir(out_csv_path.parent)\n",
    "    fields = _fieldnames_for_dataset(dataset_name)\n",
    "    with open(out_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fields)\n",
    "        writer.writeheader()\n",
    "        f.flush()\n",
    "\n",
    "        N = len(qlist)\n",
    "        first_batch_n = min(20, N)\n",
    "        batches = _chunk_slices(N, [first_batch_n, \"rest\"])\n",
    "\n",
    "        for bi, (s, e) in enumerate(batches):\n",
    "            batch = qlist[s:e]\n",
    "            for idx, q in enumerate(batch, start=s+1):\n",
    "                t0 = time.time()\n",
    "                raw = call_qwen(q, prepend_prompt)\n",
    "                elapsed = time.time() - t0\n",
    "\n",
    "                model_ans = _parse_model_answer(raw, q.get(\"options\", []))\n",
    "                correct = q.get(\"correct_answer\", \"\").strip()\n",
    "\n",
    "                row = {\n",
    "                    \"id\": q.get(\"id\"),\n",
    "                    \"testname\": dataset_name.upper(),\n",
    "                    \"question\": q.get(\"question\"),\n",
    "                    \"Chart_type\": q.get(\"Chart_type\"),\n",
    "                    \"Task\": q.get(\"Task\"),\n",
    "                    \"options\": \"; \".join(q.get(\"options\", [])),\n",
    "                    \"correct_answer\": correct,\n",
    "                    \"model_answer\": model_ans,\n",
    "                    \"is_correct\": str(model_ans.strip() == correct),\n",
    "                    \"image_path\": q.get(\"image_path\", \"\"),\n",
    "                    \"elapsed_seconds\": f\"{elapsed:.3f}\",\n",
    "                    \"response_raw\": raw.strip()\n",
    "                }\n",
    "                if dataset_name.upper() == \"CALVI\":\n",
    "                    row[\"Misleader\"] = q.get(\"Misleader\", \"\")\n",
    "                    row[\"wrong_due_to_misleader\"] = q.get(\"wrong_due_to_misleader\", \"\")\n",
    "\n",
    "                _write_row(writer, row, f)\n",
    "\n",
    "                if s == 0:\n",
    "                    first_done = idx - s\n",
    "                    if first_done == 5:\n",
    "                        if dataset_name.upper() == \"VLAT\":\n",
    "                            print(\"first 5 questions done for vlat\")\n",
    "                        else:\n",
    "                            print(\"first 5 questions done for calvi\")\n",
    "                    elif first_done == 10:\n",
    "                        if dataset_name.upper() == \"VLAT\":\n",
    "                            print(\"first next 5 done\")\n",
    "                        else:\n",
    "                            print(\"first next 5 done (calvi)\")\n",
    "\n",
    "            if bi == 0 and len(batches) > 1:\n",
    "                _sleep_between()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee06a3f-0456-4a92-92dd-efe017b84552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _outdir_for(dataset_name: str) -> Path:\n",
    "    if dataset_name.upper() == \"VLAT\":\n",
    "        return OUT_VLAT\n",
    "    elif dataset_name.upper() == \"CALVI\":\n",
    "        return OUT_CALVI\n",
    "    else:\n",
    "        raise ValueError(\"dataset_name must be 'VLAT' or 'CALVI'\")\n",
    "\n",
    "def run_experiment(dataset_name: str, json_path: Path, prompt_overrides: Optional[str] = None, runs: int = NUM_RUNS):\n",
    "    dataset_name_u = dataset_name.upper()\n",
    "    data = _load_json(json_path)\n",
    "    questions = list(data.get(\"questions\", []))\n",
    "    outdir = _outdir_for(dataset_name_u)\n",
    "    _ensure_dir(outdir)\n",
    "\n",
    "    for run_idx in range(1, runs+1):\n",
    "        if dataset_name_u == \"VLAT\":\n",
    "            seed = BASE_SEED + run_idx\n",
    "        else:\n",
    "            seed = BASE_SEED + 10_000 + run_idx\n",
    "        random.seed(seed)\n",
    "        qlist = questions[:]\n",
    "        random.shuffle(qlist)\n",
    "\n",
    "        if dataset_name_u == \"VLAT\":\n",
    "            out_csv = outdir / f\"vlat_qwen2.5vl_7b_run_{run_idx:02d}.csv\"\n",
    "        else:\n",
    "            out_csv = outdir / f\"calvi_qwen2.5vl_7b_run_{run_idx:02d}.csv\"\n",
    "\n",
    "        print(f\"Running {dataset_name_u}, run {run_idx:02d} -> {out_csv}\")\n",
    "        _eval_one_run(dataset_name_u, qlist, out_csv, run_idx, prepend_prompt=prompt_overrides)\n",
    "\n",
    "    print(f\"All {dataset_name_u} runs completed.\")\n",
    "\n",
    "def run_all(do_vlat: bool = True, do_calvi: bool = True, runs: int = NUM_RUNS):\n",
    "    if do_vlat:\n",
    "        run_experiment(\"VLAT\", VLAT_JSON, prompt_overrides=VLAT_PROMPT, runs=runs)\n",
    "    if do_calvi:\n",
    "        run_experiment(\"CALVI\", CALVI_JSON, prompt_overrides=CALVI_PROMPT, runs=runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aca7beef-6aba-4480-846f-6dec89fd524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running VLAT, run 01 -> C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\Output\\VLAT\\Qwen2.5vl_7b_Eval\\Random\\vlat_qwen2.5vl_7b_run_01.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m run_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVLAT\u001b[39m\u001b[38;5;124m\"\u001b[39m,  VLAT_JSON,  prompt_overrides\u001b[38;5;241m=\u001b[39mVLAT_PROMPT,  runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      2\u001b[0m run_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALVI\u001b[39m\u001b[38;5;124m\"\u001b[39m, CALVI_JSON, prompt_overrides\u001b[38;5;241m=\u001b[39mCALVI_PROMPT, runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(dataset_name, json_path, prompt_overrides, runs)\u001b[0m\n\u001b[0;32m     28\u001b[0m         out_csv \u001b[38;5;241m=\u001b[39m outdir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalvi_qwen2.5vl_7b_run_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_idx\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name_u\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_idx\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m     _eval_one_run(dataset_name_u, qlist, out_csv, run_idx, prepend_prompt\u001b[38;5;241m=\u001b[39mprompt_overrides)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name_u\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m runs completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m, in \u001b[0;36m_eval_one_run\u001b[1;34m(dataset_name, qlist, out_csv_path, run_index, prepend_prompt)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch, start\u001b[38;5;241m=\u001b[39ms\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     20\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 21\u001b[0m     raw \u001b[38;5;241m=\u001b[39m call_qwen(q, prepend_prompt)\n\u001b[0;32m     22\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[0;32m     24\u001b[0m     model_ans \u001b[38;5;241m=\u001b[39m _parse_model_answer(raw, q\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m, []))\n",
      "Cell \u001b[1;32mIn[6], line 80\u001b[0m, in \u001b[0;36mcall_qwen\u001b[1;34m(question, prepend_prompt)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_CHAT_API:\n\u001b[1;32m---> 80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ollama_chat(prompt, images_b64)\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ollama_generate(prompt, images_b64)\n",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m, in \u001b[0;36m_ollama_chat\u001b[1;34m(prompt, images_b64)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, json\u001b[38;5;241m=\u001b[39mpayload, timeout\u001b[38;5;241m=\u001b[39mREQUEST_TIMEOUT)\n\u001b[0;32m     15\u001b[0m r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    586\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    590\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    591\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    592\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    593\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    594\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    595\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    596\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    599\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    600\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_experiment(\"VLAT\",  VLAT_JSON,  prompt_overrides=VLAT_PROMPT,  runs=3)\n",
    "run_experiment(\"CALVI\", CALVI_JSON, prompt_overrides=CALVI_PROMPT, runs=3)\n",
    "\n",
    "# Or both:\n",
    "# run_all(do_vlat=True, do_calvi=True, runs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558c0c3-d4c2-425f-994c-81c05b5d9498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
