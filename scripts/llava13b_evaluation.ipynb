{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c44e244-cd71-47f0-b587-8cc65896773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\n",
      "VLAT JSON expected at: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\\VLAT\\vlat_skip.json\n",
      "CALVI JSON expected at: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\\CALVI\\calvi.json\n"
     ]
    }
   ],
   "source": [
    "# === Config & imports ===\n",
    "import os, io, json, time, random, traceback, base64\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Paths (relative to this notebook's folder)\n",
    "NB_DIR = Path.cwd()\n",
    "VLAT_JSON = (NB_DIR.parent / 'data' / 'VLAT' / 'vlat_skip.json')\n",
    "CALVI_JSON = (NB_DIR.parent / 'data' / 'CALVI' / 'calvi.json')\n",
    "\n",
    "# Ollama chat endpoint / model\n",
    "API_URL = 'http://127.0.0.1:11434/api/chat'  # instead of localhost\n",
    "REQUEST_TIMEOUT = 600  # seconds; first few calls can be slow\n",
    "MODEL   = 'llava:13b'\n",
    "\n",
    "# Experiment options\n",
    "NUM_RUNS     = 3         # number of repetitions over the dataset\n",
    "MAX_RETRIES  = 3         # retries for transient API errors\n",
    "RETRY_DELAY  = 2         # seconds\n",
    "TEMPERATURE  = 0.0       # deterministic\n",
    "MAX_TOKENS   = 300       # response cap (if your server honors it)\n",
    "\n",
    "# Prompts\n",
    "VLAT_PROMPT = (\n",
    "\"\"\"I am about to show you an image and ask you a multiple choice question about that image. \n",
    "Please structure your response in the following format:\n",
    "Answer: [Enter the exact text of your chosen option]\n",
    "Explanation: [Provide your reasoning]\n",
    "Select the BEST answer, based only on the chart and not external knowledge. DO NOT GUESS.\n",
    "If you are not sure about your answer or your answer is based on a guess, select \"Omit\".\n",
    "Choose your answer ONLY from the provided options.\"\"\"\n",
    ")\n",
    "CALVI_PROMPT = (\n",
    "\"\"\"I am about to show you an image and ask you a multiple choice question about that image. \n",
    "Please structure your response in the following format:\n",
    "Answer: [Enter the exact text of your chosen option(s)]\n",
    "Explanation: [Provide your reasoning]\n",
    "Select the BEST answer, based only on the chart and not external knowledge.\n",
    "Choose your answer ONLY from the provided options.\"\"\"\n",
    ")\n",
    "\n",
    "print('Notebook directory:', NB_DIR)\n",
    "print('VLAT JSON expected at:', VLAT_JSON)\n",
    "print('CALVI JSON expected at:', CALVI_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17220074-0c1e-4f58-9818-add2d1dfc071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CSV helper: minimal, single-row append with header on first write ---\n",
    "import os, csv\n",
    "\n",
    "def append_to_csv(csv_path, data_dict, fieldnames=None):\n",
    "    \"\"\"\n",
    "    Append one row (dict) to a CSV.\n",
    "    - Creates file with header on first write.\n",
    "    - Uses utf-8 and newline='' to avoid blank lines on Windows.\n",
    "    - fieldnames: optional explicit column order. Defaults to data_dict.keys().\n",
    "    \"\"\"\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "    with open(csv_path, mode=\"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=(fieldnames or list(data_dict.keys())))\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31aa418c-7ccb-452b-a3ae-f9575d259f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Utilities: ping server, image encoding, robust JSON loading ===\n",
    "def ping_ollama(url: str = API_URL) -> bool:\n",
    "    try:\n",
    "        r = requests.get(url.replace('/api/chat','/api/tags'), timeout=5)\n",
    "        return r.ok\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def b64_from_file(path: Path) -> str:\n",
    "    with open(path, 'rb') as f:\n",
    "        return base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "def resolve_image_paths(json_path: Path, questions: List[Dict[str,Any]]) -> List[Dict[str,Any]]:\n",
    "    base = json_path.parent\n",
    "    for q in questions:\n",
    "        raw = q.get('image_path', '')\n",
    "        p = Path(raw)\n",
    "        if not p.is_absolute():\n",
    "            candidates = [\n",
    "                base / p,                       # same folder as JSON\n",
    "                base / 'images' / p.name,       # a common layout\n",
    "                base.parent / p,                # one level up\n",
    "                Path.cwd() / p                  # notebook CWD (fallback)\n",
    "            ]\n",
    "            chosen = None\n",
    "            for c in candidates:\n",
    "                if c.exists():\n",
    "                    chosen = c\n",
    "                    break\n",
    "            if chosen is None:\n",
    "                # keep best-guess (relative to JSON folder) so errors are informative\n",
    "                chosen = (base / p)\n",
    "            q['image_path'] = str(chosen)\n",
    "        else:\n",
    "            q['image_path'] = str(p)\n",
    "    return questions\n",
    "\n",
    "def load_questions_file(file_path: Path) -> List[Dict[str,Any]]:\n",
    "    file_path = Path(file_path)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    # expected schema: top-level key 'questions'\n",
    "    items = data.get('questions', data)\n",
    "    if not isinstance(items, list):\n",
    "        raise ValueError('Expected a list under key \"questions\" or the file to be a list of items.')\n",
    "    return resolve_image_paths(file_path, items)\n",
    "\n",
    "def call_llava(image_path: Path, prompt: str) -> str:\n",
    "    # encode image\n",
    "    img_b64 = b64_from_file(image_path)\n",
    "    payload = {\n",
    "        'model': MODEL,\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "                'images': [img_b64]\n",
    "            }\n",
    "        ],\n",
    "        'stream': False,\n",
    "        'options': {\n",
    "            'temperature': TEMPERATURE,\n",
    "        }\n",
    "    }\n",
    "    for attempt in range(1, MAX_RETRIES+1):\n",
    "        try:\n",
    "            r = requests.post(API_URL, json=payload, timeout=REQUEST_TIMEOUT)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            return data.get('message',{}).get('content','')\n",
    "        except Exception as e:\n",
    "            if attempt == MAX_RETRIES:\n",
    "                raise\n",
    "            time.sleep(RETRY_DELAY)\n",
    "    return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "571bd355-d263-4de0-8e55-8f260146ca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running? -> True\n",
      "VLAT JSON exists? -> True\n",
      "CALVI JSON exists? -> True\n"
     ]
    }
   ],
   "source": [
    "# === Sanity checks ===\n",
    "print('Ollama running? ->', ping_ollama())\n",
    "print('VLAT JSON exists? ->', VLAT_JSON.exists())\n",
    "print('CALVI JSON exists? ->', CALVI_JSON.exists())\n",
    "\n",
    "# If these return False, fix the paths above or move your files accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf0f0cd-2e47-4b87-a34c-ddfe53b80294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample VLAT item:\n",
      "  id: 1\n",
      "  question: What was the price of a barrel of oil in February 2015?\n",
      "  image_path: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\\VLAT\\images\\LineChart.png\n",
      "Image exists? -> True\n",
      "Sample CALVI item:\n",
      "  id: 43\n",
      "  question: What is the trend sales in gift shop A from Jan to Dec?\n",
      "  image_path: C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\data\\CALVI\\images\\question43.png\n",
      "Image exists? -> True\n"
     ]
    }
   ],
   "source": [
    "# === Peek at the first question and verify its image path resolution ===\n",
    "try:\n",
    "    vlat_qs = load_questions_file(VLAT_JSON)\n",
    "    if not vlat_qs:\n",
    "        print('VLAT has 0 questions!')\n",
    "    else:\n",
    "        q0 = vlat_qs[0]\n",
    "        print('Sample VLAT item:')\n",
    "        for k in ['id','question','image_path']:\n",
    "            print(' ', k+':', q0.get(k))\n",
    "        print('Image exists? ->', Path(q0['image_path']).exists())\n",
    "except Exception as e:\n",
    "    print('Error loading VLAT:', e)\n",
    "\n",
    "try:\n",
    "    calvi_qs = load_questions_file(CALVI_JSON)\n",
    "    if not calvi_qs:\n",
    "        print('CALVI has 0 questions!')\n",
    "    else:\n",
    "        q0 = calvi_qs[0]\n",
    "        print('Sample CALVI item:')\n",
    "        for k in ['id','question','image_path']:\n",
    "            print(' ', k+':', q0.get(k))\n",
    "        print('Image exists? ->', Path(q0['image_path']).exists())\n",
    "except Exception as e:\n",
    "    print('Error loading CALVI:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f9d7446-5806-40b4-a8e7-4e8d1f3c2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Main experiment runner ===\n",
    "import csv\n",
    "from time import perf_counter\n",
    "\n",
    "def _opt_str(opts):\n",
    "    \"\"\"Convert list/dict options into a readable string for CSV.\"\"\"\n",
    "    if isinstance(opts, (list, tuple)):\n",
    "        return \" | \".join(str(x) for x in opts)\n",
    "    if isinstance(opts, dict):\n",
    "        return \" | \".join(f\"{k}) {v}\" for k, v in opts.items())\n",
    "    return \"\" if opts is None else str(opts)\n",
    "\n",
    "def run_experiment(name: str, dataset_path: Path, prompt: str, out_dir: Path = NB_DIR / \"results\"):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    questions = load_questions_file(dataset_path)\n",
    "    print(f\"Starting {name} with {len(questions)} questions...\")\n",
    "\n",
    "    for run_idx in range(1, NUM_RUNS + 1):\n",
    "        log_path = out_dir / f\"{name}_run{run_idx}.csv\"\n",
    "        print(f\"\\n--- Run {run_idx}/{NUM_RUNS} --- writing to {log_path}\")\n",
    "\n",
    "        with open(log_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(\n",
    "                f,\n",
    "                fieldnames=[\n",
    "                    \"test_name\",\n",
    "                    \"question\",\n",
    "                    \"options\",\n",
    "                    \"correct_answer\",\n",
    "                    \"llava_answer\",\n",
    "                    \"raw_response\",\n",
    "                    \"misleader\",\n",
    "                    \"is_correct\",\n",
    "                    \"elapsed_seconds\",\n",
    "                ],\n",
    "            )\n",
    "            writer.writeheader()\n",
    "\n",
    "            for i, q in enumerate(questions, 1):\n",
    "                qid = q.get(\"id\", f\"{name}_{i}\")\n",
    "                img = Path(q.get(\"image_path\", \"\"))\n",
    "                question_text = q.get(\"question\", \"\")\n",
    "                options = q.get(\"options\", q.get(\"choices\", \"\"))\n",
    "                correct = q.get(\"correct_answer\", q.get(\"answer\", \"\"))\n",
    "                misleader = q.get(\"misleader\", \"\")\n",
    "\n",
    "                try:\n",
    "                    # --- measure LLaVA call time ---\n",
    "                    t0 = perf_counter()\n",
    "                    raw_response = call_llava(img, prompt + \"\\n\\nQuestion: \" + question_text)\n",
    "                    elapsed = round(perf_counter() - t0, 3)\n",
    "\n",
    "                    # Use raw text as llava_answer (or plug in your parser if you have one)\n",
    "                    llava_answer = raw_response.strip()\n",
    "                    is_correct = str(llava_answer).strip().lower() == str(correct).strip().lower()\n",
    "\n",
    "                    writer.writerow({\n",
    "                        \"test_name\": name,\n",
    "                        \"question\": question_text,\n",
    "                        \"options\": _opt_str(options),\n",
    "                        \"correct_answer\": correct,\n",
    "                        \"llava_answer\": llava_answer,\n",
    "                        \"raw_response\": raw_response,\n",
    "                        \"misleader\": misleader,\n",
    "                        \"is_correct\": is_correct,\n",
    "                        \"elapsed_seconds\": elapsed,\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Still log the row to keep format consistent\n",
    "                    writer.writerow({\n",
    "                        \"test_name\": name,\n",
    "                        \"question\": question_text,\n",
    "                        \"options\": _opt_str(options),\n",
    "                        \"correct_answer\": correct,\n",
    "                        \"llava_answer\": \"\",\n",
    "                        \"raw_response\": f\"[exception] {e}\",\n",
    "                        \"misleader\": misleader,\n",
    "                        \"is_correct\": False,\n",
    "                        \"elapsed_seconds\": None,\n",
    "                    })\n",
    "                    print(\"Error:\", e)\n",
    "\n",
    "        print(f\"✓ Done writing {log_path}\")\n",
    "\n",
    "    print(\"All runs completed for\", name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f961b8d8-4876-4e88-a303-78bb9433f1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:55.3267157Z\",\"message\":{\"role\":\"assistant\",\"content\":\" Hello\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:55.5128007Z\",\"message\":{\"role\":\"assistant\",\"content\":\" Mel\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:55.7041346Z\",\"message\":{\"role\":\"assistant\",\"content\":\"ita\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:55.8949753Z\",\"message\":{\"role\":\"assistant\",\"content\":\"!\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:56.0691987Z\",\"message\":{\"role\":\"assistant\",\"content\":\" I\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:56.2512861Z\",\"message\":{\"role\":\"assistant\",\"content\":\"'\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:56.43096Z\",\"message\":{\"role\":\"assistant\",\"content\":\"m\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:56.6193919Z\",\"message\":{\"role\":\"assistant\",\"content\":\" just\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:56.8153763Z\",\"message\":{\"role\":\"assistant\",\"content\":\" a\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:57.0003981Z\",\"message\":{\"role\":\"assistant\",\"content\":\" computer\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:57.2055405Z\",\"message\":{\"role\":\"assistant\",\"content\":\" program\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:57.4510971Z\",\"message\":{\"role\":\"assistant\",\"content\":\",\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:57.7214351Z\",\"message\":{\"role\":\"assistant\",\"content\":\" so\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:57.9820125Z\",\"message\":{\"role\":\"assistant\",\"content\":\" I\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:58.246908Z\",\"message\":{\"role\":\"assistant\",\"content\":\" don\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:58.4900604Z\",\"message\":{\"role\":\"assistant\",\"content\":\"'\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:58.725512Z\",\"message\":{\"role\":\"assistant\",\"content\":\"t\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:58.9678234Z\",\"message\":{\"role\":\"assistant\",\"content\":\" have\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:59.1986225Z\",\"message\":{\"role\":\"assistant\",\"content\":\" feelings\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:59.5023185Z\",\"message\":{\"role\":\"assistant\",\"content\":\" or\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:59.7413821Z\",\"message\":{\"role\":\"assistant\",\"content\":\" emot\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:49:59.9792602Z\",\"message\":{\"role\":\"assistant\",\"content\":\"ions\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:00.2181247Z\",\"message\":{\"role\":\"assistant\",\"content\":\".\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:00.5585828Z\",\"message\":{\"role\":\"assistant\",\"content\":\" But\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:00.8811825Z\",\"message\":{\"role\":\"assistant\",\"content\":\" thanks\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:01.1647699Z\",\"message\":{\"role\":\"assistant\",\"content\":\" for\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:01.4024702Z\",\"message\":{\"role\":\"assistant\",\"content\":\" asking\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:01.6364086Z\",\"message\":{\"role\":\"assistant\",\"content\":\"!\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:01.9187884Z\",\"message\":{\"role\":\"assistant\",\"content\":\" How\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:02.1908721Z\",\"message\":{\"role\":\"assistant\",\"content\":\" can\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:02.4726815Z\",\"message\":{\"role\":\"assistant\",\"content\":\" I\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:02.761161Z\",\"message\":{\"role\":\"assistant\",\"content\":\" assist\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:03.1340416Z\",\"message\":{\"role\":\"assistant\",\"content\":\" you\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:03.410805Z\",\"message\":{\"role\":\"assistant\",\"content\":\" today\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:03.6610141Z\",\"message\":{\"role\":\"assistant\",\"content\":\"?\"},\"done\":false}\n",
      "{\"model\":\"llava:13b\",\"created_at\":\"2025-10-15T14:50:03.9156812Z\",\"message\":{\"role\":\"assistant\",\"content\":\"\"},\"done\":true,\"done_reason\":\"stop\",\"total_duration\":9685720200,\"load_duration\":20561900,\"prompt_eval_count\":18,\"prompt_eval_duration\":1073837700,\"eval_count\":36,\"eval_duration\":8590635400}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests, base64, json\n",
    "# simple empty chat to check response\n",
    "test = requests.post(\n",
    "    'http://127.0.0.1:11434/api/chat',\n",
    "    json={\"model\":\"llava:13b\",\"messages\":[{\"role\":\"user\",\"content\":\"hi im Melita how are you\"}]},\n",
    "    timeout=60\n",
    ")\n",
    "print(test.status_code, test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90b44bff-99f0-4989-bca2-287728a39b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting VLAT with 3 questions...\n",
      "\n",
      "--- Run 1/3 --- writing to C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\VLAT_run1.csv\n",
      "✓ Done writing C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\VLAT_run1.csv\n",
      "\n",
      "--- Run 2/3 --- writing to C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\VLAT_run2.csv\n",
      "✓ Done writing C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\VLAT_run2.csv\n",
      "\n",
      "--- Run 3/3 --- writing to C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\VLAT_run3.csv\n",
      "✓ Done writing C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\VLAT_run3.csv\n",
      "All runs completed for VLAT\n",
      "Starting CALVI with 3 questions...\n",
      "\n",
      "--- Run 1/3 --- writing to C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\CALVI_run1.csv\n",
      "✓ Done writing C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\CALVI_run1.csv\n",
      "\n",
      "--- Run 2/3 --- writing to C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\CALVI_run2.csv\n",
      "✓ Done writing C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\CALVI_run2.csv\n",
      "\n",
      "--- Run 3/3 --- writing to C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\CALVI_run3.csv\n",
      "✓ Done writing C:\\Users\\Melita\\CSE 4001\\VLM-Eval-Research\\scripts\\results\\CALVI_run3.csv\n",
      "All runs completed for CALVI\n"
     ]
    }
   ],
   "source": [
    "# === Run experiments ===\n",
    "run_experiment('VLAT', VLAT_JSON, VLAT_PROMPT)\n",
    "run_experiment('CALVI', CALVI_JSON, CALVI_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70562cc9-8a01-4237-92ce-466acc467f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
